{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b05009b",
   "metadata": {},
   "source": [
    "# Text Classification with BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10592b5f",
   "metadata": {},
   "source": [
    "The online store is launching a new service. Now users can edit and supplement product descriptions, as in wiki communities. That is, clients offer their edits and comment on the changes of others. The store needs a tool that will search for toxic comments and send them for moderation. \n",
    "\n",
    "It is required to train the model to classify comments into positive and negative. At your disposal is a data set with markup on the toxicity of edits.\n",
    "\n",
    "It is necessary to build a model with the value of the quality metric *F1* at least 0.75. \n",
    "\n",
    "\n",
    "**Data description**\n",
    "\n",
    "The data is in the file `toxic_comments.csv'. The *text* column in it contains the comment text, and *toxic* is the target attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fb7143",
   "metadata": {},
   "source": [
    "## Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "408ba156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install transformers\n",
    "# pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be45193b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm import notebook\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "RAND = 2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "003803a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = pd.read_csv('datasets\\yandex_13_toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "435e5982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0\n",
       "5  \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7  Your vandalism to the Matt Shirvington article...      0\n",
       "8  Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9  alignment on this subject and which are contra...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75390aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "toxic    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check NaN\n",
    "df_tweets.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5e86262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    159571.000000\n",
       "mean          0.101679\n",
       "std           0.302226\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.000000\n",
       "75%           0.000000\n",
       "max           1.000000\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check target column\n",
    "df_tweets['toxic'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e136314",
   "metadata": {},
   "source": [
    "The sample is not balanced. It is necessary to make a balanced sample for training and testing, especially since we will not be able to process all 159 thousand texts anyway (it will be on the CPU for a long time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d2e90a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min lenght: 6, max lenght: 5000\n"
     ]
    }
   ],
   "source": [
    "# Let's check the length of the texts (number of characters)\n",
    "ln = np.array([len(x) for x in df_tweets['text']])\n",
    "print(f'min lenght: {ln.min()}, max lenght: {ln.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26f71094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forming a balanced sample\n",
    "df_0= df_tweets.query(\"toxic == 0\").sample(n=5000, random_state=RAND)\n",
    "df_1= df_tweets.query(\"toxic == 1\").sample(n=5000, random_state=RAND)\n",
    "df_sample = pd.concat([df_0,df_1]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afb111a",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faa7b448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the tokenizer as a class object BertTokenizer()\n",
    "tokenizer = transformers.BertTokenizer(vocab_file='bert\\\\vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ca410c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "499cd50d942847d3aca83eb1a3e29d5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vectors = []\n",
    "max_n =0\n",
    "y=[]\n",
    "for i in notebook.tqdm(range(df_sample['text'].shape[0])):    \n",
    "    txt = df_sample['text'][i]\n",
    "    # Convert the text to token numbers from the dictionary\n",
    "    # the add_special_tokens argument equal to True means that to any converted text \n",
    "    # the start token (101) and the end token of the text (102) are added\n",
    "    v = tokenizer.encode(txt, add_special_tokens=True)\n",
    "    # If the text contains a lot of words, then we discard such text \n",
    "    # (otherwise we will need to complicate the model by splitting the text into pieces and back-gluing)if len(v) < 512:\n",
    "        vectors.append(v)\n",
    "        y.append(df_sample['toxic'][i])\n",
    "        if len(v) > max_n:\n",
    "            max_n=len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a156914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after tokenization, the lengths of the source texts in the corpus should be equal\n",
    "padded = np.array([i + [0]*(max_n - len(i)) for i in vectors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "781ae9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain to the model that zeros do not carry meaningful information.\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa06accb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert\\pytorch_model.bin were not used when initializing BertModel: ['fit_denses.3.bias', 'fit_denses.0.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'fit_denses.2.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'fit_denses.0.weight', 'fit_denses.1.weight', 'fit_denses.4.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'fit_denses.3.weight', 'cls.seq_relationship.bias', 'fit_denses.2.bias', 'fit_denses.4.weight', 'fit_denses.1.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Initializing the configuration​ BertConfig\n",
    "config = transformers.BertConfig.from_json_file('bert\\\\config.json')\n",
    "# initialize the class model itselfBertModel\n",
    "model = transformers.BertModel.from_pretrained('bert\\\\pytorch_model.bin', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c49d1db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9796, 509)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the size of the corpus and mask\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f1b8304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9796"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the size of the target\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b725cea1",
   "metadata": {},
   "source": [
    "The sizes match, we begin the calculation of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ccdea3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4195feac25ac42a284565da9406e832b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "        # convert data\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        # convert mask\n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # create a batch of embeddings\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        # adding the calculated embeddings to the list\n",
    "        embeddings.append(batch_embeddings[0][:,0,:].numpy())\n",
    "        \n",
    "        # --- ADDED to save memory\n",
    "        del batch\n",
    "        del attention_mask_batch\n",
    "        del batch_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e07e62a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate features\n",
    "features = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9377e67a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9700, 312)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572adee5",
   "metadata": {},
   "source": [
    "The number of feature observations corresponds to the number of observations of the target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d686d015",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    y[:len(features)],\n",
    "    test_size = 0.1,\n",
    "    random_state=2007\n",
    ")\n",
    "\n",
    "pd.DataFrame(\n",
    "    data={\n",
    "        'train': [X_train.shape, len(y_train)], \n",
    "        'test': [X_test.shape, len(y_test)] },\n",
    "    index=['X', 'y']\n",
    ")"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJoAAABMCAYAAACVmK4lAAAIpklEQVR4nO2dPW/abheHLz96pvoDkCwF9UMgGKiSHckZEkGkDhk7ZWEJCwOLWVg6dWSoBBEZGik7URmM/CEi0gX4AO56/wfbcJuYN7dxSjmXZMncto/POfx8vxDIMZRSCkF4Zf731g4Ih4EITUgFEZqQCiI0IRVEaEIqiNCEVBChCalw4EIb0TrrMd3pmim9MwOjNXoln9JkSu+sReJIRi3Oettl76CFNmoVqe981RHV7wp1U3gFj9Jl2vvM5X3Sq0e0ijtkTx0ok66lgGCzlePYClCW5bfbjlIqaPM3S3UnSik1UV0Lhe1o+7ayw/Osrpq8bWjbERNbJCe2E5wYxBhpj2tbz8EKTSmlHFsTRii0bigTR9mh4GLFpSfcVo5mY4u8/xX4wtJ9D/aD2K3uJBqTY2sPnHbOFvw/acf5r1LIHYV73CjFqGVgFOdN8dgn/qFcDuvVPXwdRo/+MFg0tOFwPIYTP6Z60aAOWN0J1aNYE2s56DnaWqY9zgyDIg5KTejuq4J2wsbxRzl/uynAUZXvSuHY/hn3l8dbLwB0RGirGI+5B+yTAjBmnHjSvB8UTmygzuOI+UPWGgGjFoZxxvhKoZSDndD+QQ+duZwF9UuOjTGOs3SwcEXXqnNZNKhjYVnAaMyU3Fu4+ioc5QpAnaIxojv5jmPXKQZDJLbD9wLADY5tUDw2uASwukyCsdNP3zHG2Nm4CjeUku+jCa+PDJ1CKojQhFQQoQmpIEITUkGEJqSCCE1IBRGakAprP7A1DCMtP4R/EP0j2rVC8zzv1Z0RDgMZOoVUEKEJqSBCE1JBhCakgghNSAURmpAKCYQ2o18xMc02btDitk1Ms0J/lsCDWZ9K213smyamqdmPtC0dc9uLtkqfxe1d2rHtK1hpJ3Srghn6GL5e9oUZ/coiJ7+TBz+f/lYJk7ouDzvGG2t/4Qj9iski3PD9Drb5gR3jXffLFc/z4renjiqDojlQ3qCpAFXuPK0+f+X2pDrlphrM9xd2Bs3A/tI1gyaqOfCU5w1Uk7LqPMVf6+/77f75q7bVduZ+oPny1FFlQp+D4+WOegqPxfi8Ux4GTQXRnMT5v8jDjvEOmlF/57GHufDjDW08dcra++Afn+dnQ7w6yYbOzAVfOmVonGKeNoAmtYvM7nbcb9ydfyLvGyWbjx4uv88und/m1O3wKQ+Qp+bdot82n80ALsNGuJ/h43mZxnDdc7fKjt9zDUseg6Z2euaCW69G6Gq+1Iwcq9HevWfX8jB7dqFZiuTEfV4yGMnDjvHma3i3FyzCzeOHO6NfGVLyBkTDvcWrzaOltJSLbeNNPEfLXNTmDjUHi8TvgjtszN9UgHzNo/bzA6ZpMix53EbEO6Pfdul80ZNEMOx94Iow8QBlIhp1n7ccPqN2Mhe31DYE5g4blM8/zn3Kvoe7H7spTc9DJpuHxnA+HD+78PDzWTs7Lg+7x+u2TcwPV9BZPOgXt5veR5dho8z5x8Wdt403+WJg9jwfn9f3GCsN8OzqCfLnGcOSh+d5lIZmZF7E7Ad3nPNxuePM1/A8j6fzOz5sMx9bRQI7s36FUwaRByKTzS8JY6OVaB7yNQbNBqemiWle8zNfXjp9RR52JF/z8Lwnzu8+xMzT4v3sV05hEO39t403odBm9K+veKBJswk0EgwXL0w+49KkFDxS+VJTe7Jh9uMOtJ5jmUw2Dw8/8UN+IBJ7PrvyuvV2VuO2Ta75og0rfw5fBB6ed0uJh8gUIj4PSeP1h+bNQnFpm9fwxdvYw68ikdBm/WuuHvwhs1Yb0OSBq+tde5MM2byWoEyWPA3CznH27EL5PX6KZ/j51dPn0tZXvsNGMLfx5xH+vGbGj7sHmqV12VllZ80V7bihfeH3i7nlWpby4LYXK8dZn3ZkqIrLw47xum1tpPDnd5vzM6S0NI8N2TrenVed4YozXLnMV0oJVp6DZnRlGdoGbeUVrnb019H7suyPtnrS7esrte3saCvL0I5+7otrnlSnrK/ikuVhvtJl2d8VedgxXt3+y/fMt6WvaJfjXVyzPl6dtb/r/PXr12al/hYz+pVvZDdOQv/U7fr0ny+4eK2bzfpUvmW53Xl8eaU8vHG87969m++/8V8GMlzU4LSd+GPOnZj94MVHKH/QOv3rO84/JbnB6+Thb4r3jXs04V/mL+rRhENBhCakgghNSAURmpAK8m+rhFSQHk1IBRGakAoiNCEVRGhCKojQhFQQoQmpIEITUuGghTZqGRiGv4XVQPS26LGgfGLQpldRnPbOYtv3g/i4VuchYbxbVYz6F9GLbE26ypoX09KYdJUVFCWbdK1FFbcX12qFu/alul3ApGtpPjvK3pCHpPEm7NFGtAy9OKr/OkmNoDfjRYGwArlIMa0pvc+XFG6qHAFH1e/R6iBWjhwwfexxH+xTOMG+7/G4R2kYj++xqicEtVDIWfeMx/oZ0TwkjTeh0ApcdS2oP/rVa0eP1LGoniQoe/ZWHFX5Psn5D8xn+KpuosXrRh0uCw7RyjPBMFOsYweJB6CQW+yz/Eb93eRyFve9x6AKs1/zajTWlBOXhwTxJp6jHZ1UsRgxngYl+Kwq+6Szae8sEJhCfYXPxhl6hzx6rAcFx3SC6sPKgeI+zsdeclT9SpdLjg0Dw3hkuapYfB52J/li4OiEqnVP77GHr7MT9khn0SFjHkuotBGPdZvV+c2Rs7QnfzTW6rJb5PaqLln48CiUuiI30muWrshDknh/eyIZKQO9P7ycBGuVgx37RfnmSddaVNvVFw//wmIgbpETvl4up5ww3t9bdU66ytqnOuJLOPbiJ2R6yeaIqBatkTriev73+YGLxhX1Pz4PyeL9ve+jTXucHV9ScBQbyjUKB07iwrCjlkHRL7LNVxGZsAH5hq2QCgf9JyghPURoQiqI0IRUEKEJqSBCE1JBhCakgghNSAURmpAKIjQhFURoQir8B0in0TOKDCkjAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "id": "bb116145",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28b1c14d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8599137931034484"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Launching a logistic regression\n",
    "\n",
    "linreg = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    dual=False, \n",
    "    tol=0.0001, \n",
    "    C=1.0, \n",
    "    fit_intercept=True, \n",
    "    intercept_scaling=1, \n",
    "    class_weight=None, \n",
    "    random_state=2007, \n",
    "    solver='lbfgs', \n",
    "    max_iter=100, \n",
    "    multi_class='auto', \n",
    "    verbose=0, \n",
    "    warm_start=False, \n",
    "    n_jobs=-1, \n",
    "    l1_ratio=None)\n",
    "\n",
    "\n",
    "\n",
    "lr_fitted = linreg.fit(X_train, y_train)\n",
    "predictions = lr_fitted.predict(X_test)\n",
    "\n",
    "\n",
    "# calc score\n",
    "f1_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97460d18",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883eebfd",
   "metadata": {},
   "source": [
    "Preform the regression with LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adb6ad5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8451612903225806"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "params = {\n",
    "   \n",
    "    'max_depth': 5,\n",
    "    'n_estimators': 60,\n",
    "    'colsample_bytree': 0.85,\n",
    "    'reg_alpha': 5.5,\n",
    "    'random_state': RAND\n",
    "}\n",
    "\n",
    "lgb_booster = LGBMClassifier(**params)\n",
    "\n",
    "\n",
    "model_fit = lgb_booster.fit(X_train, y_train)\n",
    "# make prediction\n",
    "prediction = model_fit.predict(X_test)\n",
    "\n",
    "# calc score\n",
    "f1_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a1c832",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "During the project, a chunk of 10,000 records (out of 159571) was processed, embeddings were calculated using the BERT neural network. Using logistic regression and LightGBM Classifier, models were calculated to predict the tone of the comment. The accuracy of F1 turned out to be 0.86, which is higher than baseline 0.75. It is surprising that LightGBM showed itself worse than LogReg.\n",
    "\n",
    "## Recommendations\n",
    "The notebook is calculated for about 2-3 hours. If you allocate more resources for the task of calculating embeds and use the GPU, then it will probably be possible to create a model with a large volume on a larger train sample.\n",
    "\n",
    "You can also select different classification models by doing cross-validation, as well as selecting hyperparameters.\n",
    "\n",
    "You can also choose a full BERT model with a large number of layers, it will probably give another 5 percent to the speed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29c5153",
   "metadata": {},
   "source": [
    "Other approaches are also used to work with texts. For example, transformers are now actively used (BERT and others from Sesame Street, for example, ELMO). BUT! They are not a panacea, they are not always needed, since TF-IDF or Word2Vec + models from classic ML can also cope.   \n",
    "BERT is heavy, there are many variations of it for different tasks, there are ready-made models, there are add-ons over the transformers library. If you train BERT on the GPU (you can use Google Colab or Kaggle), then it should be faster.   \n",
    "https://huggingface.co/transformers/model_doc/bert.html   \n",
    "https://t.me/renat_alimbekov    \n",
    "https://web.stanford.edu /~jurafsky/slp3/10.pdf - about encoder-decoder models, etensheny     \n",
    "https://pytorch.org/tutorials/beginner/transformer_tutorial.html - the official guide to the transformer from the creators of pytorch    \n",
    "https://transformer.huggingface.co / - chat with a transformer    \n",
    "Libraries: allennlp, fairseq, transformers, tensorflow-text — many implemented methods for NLP method transformers\n",
    "Word2Vec https://radimrehurek.com/gensim/models/word2vec.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527219da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
